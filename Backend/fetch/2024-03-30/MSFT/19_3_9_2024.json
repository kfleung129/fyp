{
    "title": "Microsoft staffer warns regulators about harmful AI content",
    "date": "3/9/2024",
    "url": "https://www.brainerddispatch.com/microsoft-staffer-warns-regulators-about-harmful-ai-content",
    "text": "ADVERTISEMENT ADVERTISEMENT ADVERTISEMENT ADVERTISEMENT A Microsoft Corp. software engineer sent letters to the company\u2019s board, lawmakers and the Federal Trade Commission warning that the tech giant is not doing enough to safeguard its AI image generation tool, Copilot Designer, from creating abusive and violent content. Shane Jones said he discovered a security vulnerability in OpenAI\u2019s latest DALL-E image generator model that allowed him to bypass guardrails that prevent the tool from creating harmful images. The DALL-E model is embedded in many of Microsoft\u2019s AI tools, including Copilot Designer. Jones said he reported the findings to Microsoft and \u201crepeatedly urged\u201d the Redmond, Washington-based company to \u201cremove Copilot Designer from public use until better safeguards could be put in place,\u201d according to a letter sent to the FTC on Wednesday that was reviewed by Bloomberg. \u201cWhile Microsoft is publicly marketing Copilot Designer as a safe AI product for use by everyone, including children of any age, internally the company is well aware of systemic issues where the product is creating harmful images that could be offensive and inappropriate for consumers,\u201d Jones wrote. \u201cMicrosoft Copilot Designer does not include the necessary product warnings or disclosures needed for consumers to be aware of these risks.\u201d In the letter to the FTC, Jones said Copilot Designer had a tendency to randomly generate an \u201cinappropriate, sexually objectified image of a woman in some of the pictures it creates.\u201d He also said the AI tool created \u201charmful content in a variety of other categories including: political bias, underaged drinking and drug use, misuse of corporate trademarks and copyrights, conspiracy theories, and religion to name a few.\u201d ADVERTISEMENT The FTC confirmed it received the letter but declined to comment further. The broadside echoes mounting concerns about the tendency of AI tools to generate harmful content. Last week, Microsoft said it was investigating reports that its Copilot chatbot was generating responses users called disturbing, including mixed messages on suicide. In February, Alphabet Inc.\u2019s flagship AI product, Gemini took heat for generating historically inaccurate scenes when prompted to create images of people. Jones also wrote to the Environmental, Social and Public Policy Committee of Microsoft\u2019s board, which includes Penny Pritzker and Reid Hoffman as members. \u201cI don\u2019t believe we need to wait for government regulation to ensure we are transparent with consumers about AI risks,\u201d Jones said in the letter. \u201cGiven our corporate values, we should voluntarily and transparently disclose known AI risks, especially when the AI product is being actively marketed to children.\u201d CNBC reported the letters\u2019 existence earlier. In a statement, Microsoft said it\u2019s \u201ccommitted to addressing any and all concerns employees have in accordance with our company policies, and appreciate employee efforts in studying and testing our latest technology to further enhance its safety.\u201d OpenAI didn\u2019t respond to a request for comment. Jones said he expressed his concerns to the company several times over the past three months. In January, he wrote to Democratic Senators Patty Murray and Maria Cantwell, who represent Washington State, and House Representative Adam Smith. In one letter, he asked lawmakers to investigate the risks of \u201cAI image generation technologies and the corporate governance and responsible AI practices of the companies building and marketing these products.\u201d The lawmakers didn\u2019t immediately respond to requests for comment. ADVERTISEMENT \u00a92024 Bloomberg L.P. Distributed by Tribune Content Agency, LLC. ADVERTISEMENT ADVERTISEMENT "
}