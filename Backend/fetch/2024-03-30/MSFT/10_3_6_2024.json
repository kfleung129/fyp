{
    "title": null,
    "date": "3/6/2024",
    "url": "https://www.theverge.com/2024/3/6/24092191/microsoft-ai-engineer-copilot-designer-ftc-safety-concerns",
    "text": "By  Emma Roth, a news writer who covers the streaming wars, consumer tech, crypto, social media, and much more. Previously, she was a writer and editor at MUO. A Microsoft engineer is bringing safety concerns about the company\u2019s AI image generator to the Federal Trade Commission, according to a report from CNBC. Shane Jones, who has worked for Microsoft for six years, wrote a letter to the FTC, stating that Microsoft \u201crefused\u201d to take down Copilot Designer despite repeated warnings that the tool is capable of generating harmful images. When testing Copilot Designer for safety issues and flaws, Jones found that the tool generated \u201cdemons and monsters alongside terminology related to abortion rights, teenagers with assault rifles, sexualized images of women in violent tableaus, and underage drinking and drug use,\u201d CNBC reports. Additionally, Copilot Designer reportedly generated images of Disney characters, such as Elsa from Frozen, in scenes at the Gaza Strip \u201cin front of wrecked buildings and \u2018free Gaza\u2019 signs.\u201d It also created images of Elsa wearing an Israel Defense Forces uniform while holding a shield with Israel\u2019s flag. The Verge was able to generate similar images using the tool. Jones has been trying to warn Microsoft about DALLE-3, the model used by Copilot Designer, since December, CNBC says. He posted an open letter about the issues on LinkedIn, but he was reportedly contacted by Microsoft\u2019s legal team to remove the post, which he did. \u201cOver the last three months, I have repeatedly urged Microsoft to remove Copilot Designer from public use until better safeguards could be put in place,\u201d Jones wrote in the letter obtained by CNBC. \u201cAgain, they have failed to implement these changes and continue to market the product to \u2018Anyone. Anywhere. Any Device.\u2019\u201d In a statement to The Verge, Microsoft spokesperson Frank Shaw says the company is \u201ccommitted to addressing any and all concerns employees have in accordance with\u201d Microsoft\u2019s policies. \u201cWhen it comes to safety bypasses or concerns that could have a potential impact on our services or our partners, we have established in-product user feedback tools and robust internal reporting channels to properly investigate, prioritize and remediate any issues, which we recommended that the employee utilize so we could appropriately validate and test his concerns.\u201d Shaw also says that Microsoft has \u201cfacilitated meetings with product leadership and our Office of Responsible AI to review these reports.\u201d In January, Jones wrote to a group of US senators about his concerns after Copilot Designer generated explicit images of Taylor Swift, which spread rapidly across X. Microsoft CEO Satya Nadella called the images \u201calarming and terrible\u201d and said the company would work on adding more safety guardrails. Last month, Google temporarily disabled its own AI image generator when users found that it created pictures of racially diverse Nazis and other historically inaccurate images. Update March 6th, 6:09PM ET: Added a statement from Microsoft. / Sign up for Verge Deals to get deals on products we've tested sent to your inbox daily. The Verge is a vox media network \u00a9 2024 Vox Media, LLC. All Rights Reserved "
}