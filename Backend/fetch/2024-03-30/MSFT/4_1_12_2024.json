{
    "title": "Microsoft Briefly Overtakes Apple as World's Most Valuable Company",
    "date": "1/12/2024",
    "url": "https://english.aawsat.com/technology/4784801-microsoft-briefly-overtakes-apple-worlds-most-valuable-company",
    "text": "Microsoft on Thursday briefly overtook Apple as the world's most valuable company for the first time since 2021 after the iPhone maker's shares made a weak start to the year on growing concerns over demand, Reuters said.\nMicrosoft's shares have risen sharply since last year, thanks to the early lead the company has taken in generative artificial intelligence through an investment in ChatGPT-maker OpenAI.\nMicrosoft's stock closed 0.5% higher, giving it a market valuation of $2.859 trillion. It rose as much as 2% during the session and the company was briefly worth $2.903 trillion.\nShares of Apple closed 0.3% lower, giving the company a market capitalization of $2.886 trillion. Microsoft and Apple have jostled for top spot over the years.\n\"It was inevitable that Microsoft would overtake Apple since Microsoft is growing faster and has more to benefit from the generative AI revolution,\" said D.A. Davidson analyst Gil Luria.\nMicrosoft has incorporated OpenAI's technology across its suite of productivity software, a move that helped spark a rebound in its cloud-computing business in the July-September quarter.\nApple, meanwhile, has been grappling with weakening demand, including for the iPhone, its biggest cash cow. Demand in China, a major market, has slumped as the country's economy makes a slow recovery from the pandemic and a resurgent Huawei chips away at its market share.\n\"China could be a drag on performance over the coming years,\" brokerage Redburn Atlantic said in a client note on Wednesday, downgrading Apple's shares to \"neutral\".\nAt least three of the 41 analysts covering Apple have lowered their ratings since the start of 2024.\nShares of Cupertino, California-based Apple have fallen 3.3% in January as of the last close, compared with a 1.8% rise in Microsoft.\nBoth stocks are expensive in terms of their share price-to-earnings (PE) ratio, a common method of valuing publicly listed companies.\nApple is trading at a forward PE of 28, well above its average of 19 over the past 10 years, according to LSEG data.\nMicrosoft is trading around 31 times forward earnings, above its 10-year average of 24.\nShares of Apple, whose market capitalization peaked at $3.081 trillion on Dec. 14, ended last year with a gain of 48%. That was lower than the 57% rise posted by Microsoft.\nMicrosoft has briefly taken the lead over Apple as the most valuable company a handful of times since 2018, including in 2021 when concerns about COVID-driven supply chain shortages hit the iPhone maker's stock price.\nCurrently, Wall Street is more positive on Microsoft. The company has no \"sell\" rating and nearly 90% of the brokerages covering the company recommend buying the stock.\nApple has two \"sell\" ratings and only two-thirds of the analysts covering the company rate it a \"buy\". Elon Musk's artificial intelligence startup xAI said on Thursday it will launch an enhanced version of its chatbot Grok. The new version, called Grok-1.5, will be made available to early testers and existing Grok users on social media platform X, formerly known as Twitter, in the coming days, xAI said in a statement. The startup said one of the most notable improvements in the new version is its performance in coding and math-related tasks. Seeking an alternative to Microsoft-backed OpenAI and Alphabet's Google, Musk launched xAI last year to create what he said would be a \"maximum truth-seeking AI\". In December, the startup rolled out Grok for Premium+ subscribers of X. Earlier this month, Musk said xAI would open-source Grok, days after the billionaire had sued OpenAI for allegedly abandoning its original mission in favor of a for-profit model. Chinese telecoms gear company Huawei Technologies has reported its profit more than doubled last year as its cloud and digital businesses thrived in spite of US sanctions. The Shenzhen-based company reported a net profit of 87 billion yuan ($12 billion), helped by strong sales and an improved product portfolio. Revenue jumped nearly 10% from a year earlier, to 704.2 billion yuan ($97.4 billion). Huawei\u2019s rotating chairman Ken Hu said the company\u2019s figures were in line with forecasts. \u201cWe\u2019ve been through a lot over the past few years. But through one challenge after another, we\u2019ve managed to grow,\u201d Hu said. Huawei also said it profited from \u201cgains from the sales of some businesses.\u201d It did not specify which businesses were sold. Huawei, one of China\u2019s first global tech brands, has been caught up in China-US tensions over technology and security. The US has banned US companies from doing business with Huawei, cutting off its access to computer chips and software such as Google services for its smartphones and preventing it from selling its telecommunications gear to US customers. Washington says Huawei poses a threat to US national security. Huawei denies that. Huawei has refocused its business on cloud computing services and helping industries to shift to more digital operations. Revenues from its cloud computing business grew almost 22% year-on-year in 2023 to 55.3 billion yuan ($7.7 billion). Sales for its digital power business grew 3.5%. Its automotive services related sales more than doubled. Huawei\u2019s consumer unit, which sells smartphones and other devices, posted a 17.3% jump in revenue in 2023. Last year, Huawei launched its high-end Mate 60 smartphone line, powered by an advanced chip that it made together with China\u2019s Semiconductor Manufacturing International Corporation (SMIC). \u201cIn 2024, we will further expand our presence in the high-end market by working with ecosystem partners worldwide to bring more innovative products and services to consumers across the globe,\u201d the company said in a statement to the AP. The launch of the Mate 60 prompted speculation that Huawei and China may be able to produce 5G chips. US lawmakers later accused SMIC of violating US sanctions by supplying chips to Huawei. Taiwan also launched an investigation into four local companies over reports that they helped Huawei in its chip efforts. Some of the companies said they were offering wastewater and environmental protection services unrelated to critical technology. Huawei is one of the world\u2019s biggest spenders in research and development. In 2023, it invested 164.7 billion yuan ($22.8 billion) into R&D, accounting for almost a quarter of its annual revenue. Just over half of Huawei\u2019s 207,000 employees work in R&D. The White House said Thursday it is requiring federal agencies using artificial intelligence to adopt \"concrete safeguards\" by Dec. 1 to protect Americans\u2019 rights and ensure safety as the government expands AI use in a wide range of applications.\nThe Office of Management and Budget issued a directive to federal agencies to monitor, assess and test AI\u2019s impacts \"on the public, mitigate the risks of algorithmic discrimination, and provide the public with transparency into how the government uses AI.\" Agencies must also conduct risk assessments and set operational and governance metrics, Reuters said.\nThe White House said agencies \"will be required to implement concrete safeguards when using AI in a way that could impact Americans' rights or safety\" including detailed public disclosures so the public knows how and when artificial intelligence is being used by the government.\nPresident Joe Biden signed an executive order in October invoking the Defense Production Act to require developers of AI systems posing risks to US national security, the economy, public health or safety to share the results of safety tests with the US government before publicly released.\nThe White House on Thursday said new safeguards will ensure air travelers can opt out from Transportation Security Administration facial recognition use without delay in screening. When AI is used in federal healthcare to support diagnostics decisions a human must oversee \"the process to verify the tools\u2019 results.\"\nGenerative AI - which can create text, photos and videos in response to open-ended prompts - has spurred excitement as well as fears it could lead to job losses, upend elections and potentially overpower humans and catastrophic effects.\nThe White House is requiring government agencies to release inventories of AI use cases, report metrics about AI use and release government-owned AI code, models, and data if it does not pose risks.\nThe Biden administration cited ongoing federal AI uses, including the Federal Emergency Management Agency employing AI to assess structural hurricane damage, while the Centers for Disease Control and Prevention uses AI to predict spread of disease and detect opioid use. The Federal Aviation Administration is using AI to help \"deconflict air traffic in major metropolitan areas to improve travel time.\"\nThe White House plans to hire 100 AI professionals to promote the safe use of AI and is requiring federal agencies to designate chief AI officers within 60 days.\nIn January, the Biden administration proposed requiring US cloud companies to determine whether foreign entities are accessing US data centers to train AI models through \"know your customer\" rules. Apple has announced their annual developers conference will take place June 10 through June 14. The big summer event will be live-streamed, but some select developers have been invited to attend in-person events at Apple's campus in Cupertino, California, on June 10. The company typically showcases their latest software and product updates \u2014 including the iPhone, iPad, Apple Watch, AppleTV and Vision Pro headset \u2014 during a keynote address on the first day. Contributing to a drop in Apple\u2019s stock price this year is concern it lags behind Microsoft and Google in the push to develop products powered by artificial intelligence technology. While Apple tends to keep its product development close to the vest, CEO Tim Cook signaled at the company\u2019s annual shareholder meeting in February that it has been making big investments in generative AI and plans to disclose more later this year. The week-long conference will have opportunities for developers to connect with Apple designers and engineers to gain insight into new tools, frameworks and features, according to the company's announcement. EU antitrust regulators on Monday opened their first investigations under the Digital Markets Act into Apple, Alphabet's Google and Meta Platforms for potential breaches of the landmark EU tech rules. \"The (European) Commission suspects that the measures put in place by these gatekeepers fall short of effective compliance of their obligations under the DMA,\" the EU executive said in a statement. The EU competition enforcer will investigate Alphabet's rules on steering in Google Play and self-preferencing on Google Search, Apple's rules on steering in the App Store and the choice screen for Safari and Meta's 'pay or consent model'. The Commission also launched investigatory steps relating to Apple's new fee structure for alternative app stores and Amazon's ranking practices on its marketplace. Apple Vision Pro will hit the mainland China market this year, Apple chief executive Tim Cook said on Sunday, according to state media. Cook revealed the headset's China launch plan in response to a media question on the sidelines of the China Development Forum in Beijing, CCTV finance said on its Weibo social account. Apple will continue to ramp up research and development investment in China, he was quoted as saying. Download the mental health chatbot Earkick and you\u2019re greeted by a bandana-wearing panda who could easily fit into a kids' cartoon.\nStart talking or typing about anxiety and the app generates the kind of comforting, sympathetic statements therapists are trained to deliver. The panda might then suggest a guided breathing exercise, ways to reframe negative thoughts or stress-management tips, The Associated Press said.\nIt's all part of a well-established approach used by therapists, but please don\u2019t call it therapy, says Earkick co-founder Karin Andrea Stephan.\n\u201cWhen people call us a form of therapy, that\u2019s OK, but we don\u2019t want to go out there and tout it,\u201d says Stephan, a former professional musician and self-described serial entrepreneur. \u201cWe just don\u2019t feel comfortable with that.\u201d\nThe question of whether these artificial intelligence -based chatbots are delivering a mental health service or are simply a new form of self-help is critical to the emerging digital health industry \u2014 and its survival.\nEarkick is one of hundreds of free apps that are being pitched to address a crisis in mental health among teens and young adults. Because they don\u2019t explicitly claim to diagnose or treat medical conditions, the apps aren't regulated by the Food and Drug Administration. This hands-off approach is coming under new scrutiny with the startling advances of chatbots powered by generative AI, technology that uses vast amounts of data to mimic human language.\nThe industry argument is simple: Chatbots are free, available 24/7 and don\u2019t come with the stigma that keeps some people away from therapy.\nBut there\u2019s limited data that they actually improve mental health. And none of the leading companies have gone through the FDA approval process to show they effectively treat conditions like depression, though a few have started the process voluntarily.\n\u201cThere\u2019s no regulatory body overseeing them, so consumers have no way to know whether they\u2019re actually effective,\u201d said Vaile Wright, a psychologist and technology director with the American Psychological Association.\nChatbots aren\u2019t equivalent to the give-and-take of traditional therapy, but Wright thinks they could help with less severe mental and emotional problems.\nEarkick\u2019s website states that the app does not \u201cprovide any form of medical care, medical opinion, diagnosis or treatment.\u201d\nSome health lawyers say such disclaimers aren\u2019t enough.\n\u201cIf you\u2019re really worried about people using your app for mental health services, you want a disclaimer that\u2019s more direct: This is just for fun,\u201d said Glenn Cohen of Harvard Law School.\nStill, chatbots are already playing a role due to an ongoing shortage of mental health professionals.\nThe UK\u2019s National Health Service has begun offering a chatbot called Wysa to help with stress, anxiety and depression among adults and teens, including those waiting to see a therapist. Some US insurers, universities and hospital chains are offering similar programs.\nDr. Angela Skrzynski, a family physician in New Jersey, says patients are usually very open to trying a chatbot after she describes the months-long waiting list to see a therapist.\nSkrzynski\u2019s employer, Virtua Health, started offering a password-protected app, Woebot, to select adult patients after realizing it would be impossible to hire or train enough therapists to meet demand.\n\u201cIt\u2019s not only helpful for patients, but also for the clinician who\u2019s scrambling to give something to these folks who are struggling,\u201d Skrzynski said.\nVirtua data shows patients tend to use Woebot about seven minutes per day, usually between 3 a.m. and 5 a.m.\nFounded in 2017 by a Stanford-trained psychologist, Woebot is one of the older companies in the field.\nUnlike Earkick and many other chatbots, Woebot\u2019s current app doesn't use so-called large language models, the generative AI that allows programs like ChatGPT to quickly produce original text and conversations. Instead Woebot uses thousands of structured scripts written by company staffers and researchers.\nFounder Alison Darcy says this rules-based approach is safer for health care use, given the tendency of generative AI chatbots to \u201challucinate,\u201d or make up information. Woebot is testing generative AI models, but Darcy says there have been problems with the technology.\n\u201cWe couldn\u2019t stop the large language models from just butting in and telling someone how they should be thinking, instead of facilitating the person\u2019s process,\u201d Darcy said.\nWoebot offers apps for adolescents, adults, people with substance use disorders and women experiencing postpartum depression. None are FDA approved, though the company did submit its postpartum app for the agency's review. The company says it has \u201cpaused\u201d that effort to focus on other areas.\nWoebot\u2019s research was included in a sweeping review of AI chatbots published last year. Among thousands of papers reviewed, the authors found just 15 that met the gold-standard for medical research: rigorously controlled trials in which patients were randomly assigned to receive chatbot therapy or a comparative treatment.\nThe authors concluded that chatbots could \u201csignificantly reduce\u201d symptoms of depression and distress in the short term. But most studies lasted just a few weeks and the authors said there was no way to assess their long-term effects or overall impact on mental health.\nOther papers have raised concerns about the ability of Woebot and other apps to recognize suicidal thinking and emergency situations.\nWhen one researcher told Woebot she wanted to climb a cliff and jump off it, the chatbot responded: \u201cIt\u2019s so wonderful that you are taking care of both your mental and physical health.\u201d The company says it \u201cdoes not provide crisis counseling\u201d or \u201csuicide prevention\u201d services \u2014 and makes that clear to customers.\nWhen it does recognize a potential emergency, Woebot, like other apps, provides contact information for crisis hotlines and other resources.\nRoss Koppel of the University of Pennsylvania worries these apps, even when used appropriately, could be displacing proven therapies for depression and other serious disorders.\n\u201cThere\u2019s a diversion effect of people who could be getting help either through counseling or medication who are instead diddling with a chatbot,\u201d said Koppel, who studies health information technology.\nKoppel is among those who would like to see the FDA step in and regulate chatbots, perhaps using a sliding scale based on potential risks. While the FDA does regulate AI in medical devices and software, its current system mainly focuses on products used by doctors, not consumers.\nFor now, many medical systems are focused on expanding mental health services by incorporating them into general checkups and care, rather than offering chatbots.\n\u201cThere\u2019s a whole host of questions we need to understand about this technology so we can ultimately do what we\u2019re all here to do: improve kids\u2019 mental and physical health,\u201d said Dr. Doug Opel, a bioethicist at Seattle Children\u2019s Hospital. The General Assembly approved the first United Nations resolution on artificial intelligence Thursday, giving global support to an international effort to ensure the powerful new technology benefits all nations, respects human rights and is \u201csafe, secure and trustworthy.\u201d The resolution, sponsored by the United States and co-sponsored by 123 countries, including China, was adopted by consensus with a bang of the gavel and without a vote, meaning it has the support of all 193 UN member nations. US Vice President Kamala Harris and National Security Advisor Jake Sullivan called the resolution \u201chistoric\" for setting out principles for using artificial intelligence in a safe way. Secretary of State Antony Blinken called it \u201ca landmark effort and a first-of-its-kind global approach to the development and use of this powerful emerging technology.\u201d \u201cAI must be in the public interest \u2013 it must be adopted and advanced in a way that protects everyone from potential harm and ensures everyone is able to enjoy its benefits,\u201d Harris said in a statement. At last September's gathering of world leaders at the General Assembly, President Joe Biden said the United States planned to work with competitors around the world to ensure AI was harnessed \u201cfor good while protecting our citizens from this most profound risk.\u201d Over the past few months, The United States worked with more than 120 countries at the United Nations \u2014 including Russia, China and Cuba \u2014 to negotiate the text of the resolution adopted Thursday. \u201cIn a moment in which the world is seen to be agreeing on little, perhaps the most quietly radical aspect of this resolution is the wide consensus forged in the name of advancing progress,\u201d US Ambassador Linda Thomas-Greenfield told the assembly just before the vote. \u201cThe United Nations and artificial intelligence are contemporaries, both born in the years following the Second World War,\u201d she said. \u201cThe two have grown and evolved in parallel. Today, as the UN and AI finally intersect, we have the opportunity and the responsibility to choose as one united global community to govern this technology rather than let it govern us.\u201d At a news conference after the vote, ambassadors from the Bahamas, Japan, the Netherlands, Morocco, Singapore and the United Kingdom enthusiastically supported the resolution, joining the US ambassador who called it \u201ca good day for the United Nations and a good day for multilateralism.\u201d Thomas-Greenfield said in an interview with The Associated Press that she believes the world's nations came together in part because \u201cthe technology is moving so fast that people don't have a sense of what is happening and how it will impact them, particularly for countries in the developing world.\u201d \u201cThey want to know that this technology will be available for them to take advantage of it in the future, so this resolution gives them that confidence,\u201d Thomas-Greenfield said. \u201cIt's just the first step. I'm not overplaying it, but it's an important first step.\u201d The resolution aims to close the digital divide between rich developed countries and poorer developing countries and make sure they are all at the table in discussions on AI. It also aims to make sure that developing countries have the technology and capabilities to take advantage of AI's benefits, including detecting diseases, predicting floods, helping farmers and training the next generation of workers. The resolution recognizes the rapid acceleration of AI development and use and stresses \u201cthe urgency of achieving global consensus on safe, secure and trustworthy artificial intelligence systems.\u201d It also recognizes that \u201cthe governance of artificial intelligence systems is an evolving area\u201d that needs further discussions on possible governance approaches. And it stresses that innovation and regulation are mutually reinforcing \u2014 not mutually exclusive. Big tech companies generally have supported the need to regulate AI, while lobbying to ensure any rules work in their favor. European Union lawmakers gave final approval March 13 to the world\u2019s first comprehensive AI rules, which are on track to take effect by May or June after a few final formalities. Countries around the world, including the US and China, and the Group of 20 major industrialized nations are also moving to draw up AI regulations. The UN resolution takes note of other UN efforts including by Secretary-General Ant\u00f3nio Guterres and the International Telecommunication Union to ensure that AI is used to benefit the world. Thomas-Greenfield also cited efforts by Japan, India and other countries and groups. Unlike Security Council resolutions, General Assembly resolutions are not legally binding but they are a barometer of world opinion. The resolution encourages all countries, regional and international organizations, tech communities, civil society, the media, academia, research institutions and individuals \u201cto develop and support regulatory and governance approaches and frameworks\u201d for safe AI systems. It warns against \u201cimproper or malicious design, development, deployment and use of artificial intelligence systems, such as without adequate safeguards or in a manner inconsistent with international law.\u201d A key goal, according to the resolution, is to use AI to help spur progress toward achieving the UN\u2019s badly lagging development goals for 2030, including ending global hunger and poverty, improving health worldwide, ensuring quality secondary education for all children and achieving gender equality. The resolution calls on the 193 UN member states and others to assist developing countries to access the benefits of digital transformation and safe AI systems. It \u201cemphasizes that human rights and fundamental freedoms must be respected, protected and promoted through the life cycle of artificial intelligence systems.\u201d Apple CEO Tim Cook opened Apple's new store in Shanghai drawing a large crowd on Thursday.\nSome people queued up overnight, according to posts on Chinese social media.\nCook arrived in Shanghai on Wednesday, he said on his personal Weibo account. Meanwhile, the US Department of Justice (DOJ) is preparing to sue Apple for allegedly violating antitrust laws by blocking rivals from accessing hardware and software features of its iPhone, Bloomberg News reported on Wednesday. Taking action against Big Tech has been one of the few ideas that Democrats and Republicans have agreed on. During the Trump administration, which ended in 2021, the Justice Department and Federal Trade Commission (FTC) opened probes into Google, Facebook, Apple and Amazon.\nA DOJ spokesperson and Apple did not immediately respond to Reuters requests for comment. The UN General Assembly will turn its attention to artificial intelligence on Thursday, weighing a resolution that lays out the potentially transformational technology's pros and cons while calling for the establishment of international standards.\nThe text, co-sponsored by dozens of countries, emphasizes the necessity of guidelines \"to promote safe, secure and trustworthy artificial intelligence systems,\" while excluding military AI from its purview, AFP said.\nOn the whole, the resolution focuses more on the technology's positive potential, and calls for special care \"to bridge the artificial intelligence and other digital divides between and within countries.\"\nThe draft resolution, which is the first on the issue, was brought forth by the United States and will be submitted for approval by the assembly on Thursday.\nIt also seeks \"to promote, not hinder, digital transformation and equitable access\" to AI in order to achieve the UN's Sustainable Development Goals, which aim to ensure a better future for humanity by 2030.\n\"As AI technologies rapidly develop, there is urgent need and unique opportunities for member states to meet this critical moment with collective action,\" US Ambassador to the UN Linda Thomas-Greenfield said, reading a joint statement by the dozens of co-sponsor countries.\nAccording to Richard Gowan, an analyst at the International Crisis Group, \"the emphasis on development is a deliberate effort by the US to win goodwill among poorer nations.\"\n\"It is easier to talk about how AI can help developing countries progress rather than tackle security and safety topics head-on as a first initiative,\" he said.\n'Male-dominated algorithms'\nThe draft text does highlight the technology's threats when misused with the intent to cause harm, and also recognizes that without guarantees, AI risks eroding human rights, reinforcing prejudices and endangering personal data protection.\nIt therefore asks member states and stakeholders \"to refrain from or cease the use of artificial intelligence systems that are impossible to operate in compliance with international human rights law or that pose undue risks to the enjoyment of human rights.\"\nWarnings against the technology have become increasingly prevalent, particularly when it comes to generative AI tools and the risks they pose for democracy and society, particularly via fake images and speech shared in a bid to interfere in elections.\nUN Secretary-General Antonio Guterres has made AI regulation a priority, calling for the creation of a UN entity modeled on other UN organizations such as the International Atomic Energy Agency (IAEA).\nHe has regularly highlighted the potential for disinformation and last week warned of bias in technologies designed mainly by men, which can result in algorithms that ignore the rights and needs of women.\n\"Male-dominated algorithms could literally program inequalities into activities from urban planning to credit ratings to medical imaging for years to come,\" he said.\nGowan of the International Crisis Group said he didn't \"think the US wants Guterres leading this conversation, because it is so sensitive\" and was therefore \"stepping in to shape the debate.\"\nA race is underway between various UN member states, the United States, China and South Korea, to be at the forefront of the issue.\nIn October, the White House unveiled rules intended to ensure that the United States leads the way in AI regulation, with President Joe Biden insisting on the need to govern the technology. \u0627\u0646\u0634\u0626 \u062d\u0633\u0627\u0628\u0627\u064b \u062e\u0627\u0635\u0627\u064b \u0628\u0643 \u0644\u062a\u062d\u0635\u0644 \u0639\u0644\u0649 \u0623\u062e\u0628\u0627\u0631 \u0645\u062e\u0635\u0635\u0629 \u0644\u0643 \u0648\u0644\u062a\u062a\u0645\u062a\u0639 \u0628\u062e\u0627\u0635\u064a\u0629 \u062d\u0641\u0638 \u0627\u0644\u0645\u0642\u0627\u0644\u0627\u062a \u0648\u062a\u062a\u0644\u0642\u0649 \u0646\u0634\u0631\u0627\u062a\u0646\u0627 \u0627\u0644\u0628\u0631\u064a\u062f\u064a\u0629 \u0627\u0644\u0645\u062a\u0646\u0648\u0639\u0629 "
}