{
    "title": "AMD explains how easy it is to run local AI chat powered by Ryzen CPUs and \nRadeon GPUs",
    "date": "3/9/2024",
    "url": "https://videocardz.com/newz/amd-explains-how-easy-it-is-to-run-local-ai-chat-powered-by-ryzen-cpus-and-radeon-gpus",
    "text": "AMD guides how to run local AI chats with their hardware.  AMD does not have its own tool, like NVIDIA Chat with RTX. NVIDIA came up with a simple tool that can be used to run locally smaller LLM (Large Language Models) powered by GeForce GPUs. While AMD has no such tool, the company suggests one should try using 3rd party software that runs on CPUs and GPUs. AMD Ryzen 7040 \u201cPhoenix\u201d and 8040 \u201cHawk Point\u201d are equipped with XDNA AI accelerator, which can offer anything from 10 TOPS to 16 TOPS (Trillion of operations per second) of AI inference. Soon, those AI processors will be utilized broadly and thanks to upcoming changes to Windows, the importance of AI cores will only grow. Meanwhile, rather than developing their own tool, AMD recommends that users check the LM Studio software, which is a closed-source, cross-platform,\u00a0and cross-vendor solution. It also comes with easier model management, but also many options that Chat with RTX simply does not have.   LM Studio, Source: VideoCardz  LM Studio works with Apple M-Series CPUs that have AVX2 support and can also take advantage of AMD and NVIDIA GPU acceleration. For GPUs, the tool has a 16GB VRAM recommendation, while CPU-based ML algorithms should have at least 6GB of memory available. The biggest advantage of this solution over any online models is that it runs locally, and no data is collected and used. The company puts a lot of emphasis on the private use of this software and how they care about privacy. To use LM Studio on AMD hardware, one must choose between LM Studio and LM Studio ROCm Preview. The latter is optimized for Radeon RX 7000 GPUs. Hopefully, it will be integrated into the main branch at some point. Once you download the tool, you should run it and find the proper models you are eager to work with: If you have an AMD\u00a0Ryzen AI PC\u00a0you can start chatting! If you have an AMD\u00a0Radeon\u2122 graphics card, please: Check \u201cGPU Offload\u201d on the right-hand side panel. Move the slider all the way to \u201cMax\u201d. Make sure AMD ROCm\u2122 is being shown as the detected GPU type.   ROCm support, Source: AMD  It is worth noting that the tool is not specifically optimized for AMD XDNA or Intel NPU AI accelerators. It does, however, use OpenCL for AMD APU/CPUs, which have integrated graphics. Source: AMD, LM Studio We may earn an affiliate commission through Amazon and Newegg links. This website relies on third-party cookies for advertisement, comments and social media integration. Check our Privacy and Cookie Policy for details. You can contact us through our contact page or provide a tip through this page. Copyright \u00a9 2024 \u00b7 VideoCardz.com "
}