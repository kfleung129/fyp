{
    "title": "First crack in Nvidia AI wall? Meta set to use own AI chips in its servers \nin 2024 \u2014 but it will still use Nvidia H100 GPUs ...",
    "date": "2/11/2024",
    "url": "https://www.techradar.com/pro/first-crack-in-nvidia-ai-wall-meta-set-to-use-its-own-ai-chips-in-its-servers-in-2024-but-it-will-still-use-nvidia-h100-gpus-as-well-in-its-datacenters-for-now",
    "text": "When you purchase through links on our site, we may earn an affiliate commission. Here\u2019s how it works. Meta's new chip, Artemis, is designed to run AI inference tasks Meta Platforms, the parent company of Facebook, plans to deploy its own custom-designed artificial intelligence chips, codenamed Artemis, into its data centers this year, according to an internal document seen by Reuters. This move could potentially reduce Meta's dependence on Nvidia's market dominant H100 chips and control the escalating costs of running AI workloads. Meta has been investing billions of dollars to boost its computing capacity for the power-hungry generative AI products that it is integrating into services such as Facebook, Instagram, and WhatsApp. \u00a0This involves acquiring specialized chips and reconfiguring data centers to accommodate them. According to Dylan Patel, founder of the silicon research group SemiAnalysis, the successful deployment of Meta's own chip could potentially save the company hundreds of millions of dollars in annual energy costs and billions in chip purchasing costs. NVIDIA Tesla M40 24GB Module: $240 at Amazon The NVIDIA Tesla M40 GPU Accelerator is the world's fastest accelerator for deep learning training. It provides accurate speech recognition, deep understanding in video and natural language content and better detection of anomalies in medical images. Despite this move toward self-reliance, Meta will continue to use Nvidia's H100 GPUs in its data centers for the foreseeable future. CEO Mark Zuckerberg has stated that by the end of this year, the company plans to have roughly 350,000 H100 processors in service. The deployment of its own chip marks a positive turn for Meta's in-house AI silicon project, following a decision in 2022 to discontinue the chip's first iteration in favor of Nvidia's GPUs. The new chip, Artemis, like its predecessor, is designed for AI inference, which involves using algorithms to make ranking judgments and generate responses to user prompts. \"We see our internally developed accelerators to be highly complementary to commercially available GPUs in delivering the optimal mix of performance and efficiency on Meta-specific workloads,\" a Meta spokesperson said. Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! While Meta's move to reduce its dependence on Nvidia's processors could perhaps signal the first crack in Nvidia's AI wall, it's clear that for now, Nvidia's GPUs will continue to play a significant role in Meta's AI infrastructure. Wayne Williams is a freelancer writing news for TechRadar Pro. He has been writing about computers, technology, and the web for 30 years. In that time he wrote for most of the UK\u2019s PC magazines, and launched, edited and published a number of them too. How AI leaders are reducing their ecological impact Integrating continuous testing for digital success Samsung can't blame Apple's iPhone monopoly for a lifetime of terrible software By Craig HaleMarch 28, 2024 By James IdeMarch 28, 2024 By Rhys WoodMarch 28, 2024 By Sead Fadilpa\u0161i\u0107March 28, 2024 By Marc McLarenMarch 28, 2024 By Alex BlakeMarch 28, 2024 By Rhys WoodMarch 28, 2024 By Sead Fadilpa\u0161i\u0107March 28, 2024 By James IdeMarch 28, 2024 By Mackenzie FrazierMarch 28, 2024 By Kristina TerechMarch 28, 2024 TechRadar is part of Future US Inc, an international media group and leading digital publisher. Visit our corporate site. \u00a9\nFuture US, Inc. Full 7th Floor, 130 West 42nd Street,\nNew York,\nNY 10036. "
}