{
    "title": null,
    "date": "3/19/2024",
    "url": "https://theedgemalaysia.com/node/705235",
    "text": "SAN JOSE, California (March 20): Nvidia's stock climbed on Tuesday after the heavyweight chipmaker said its new flagship artificial intelligence (AI) processor is expected to ship later this year and chief executive officer Jensen Huang said he is chasing a data data market potentially greater than US$250 billion (RM1.18 trillion). Nvidia's stock rose nearly 2% to US$901 after Huang and chief financial officer Colette Kress answered questions from investors at the company's annual developer conference in San Jose, California. The shares had dipped nearly 4% earlier in the day. \"We think we're going to come to market later this year,\" Kress said, referring to the company's new AI chip, which the company debuted on Monday. Huang estimated that companies operating data centres will spend more than US$250 billion a year to upgrade them with accelerated computing components that Nvidia specialises in developing. He said that market was growing by as much as 25% a year. Nvidia is shifting from selling single chips to selling total systems, potentially winning a larger chunk of spending within data centers. \"Nvidia doesn't build chips, it builds data centres,\" Huang said. Called Blackwell, Nvidia's new processor combines two squares of silicon the size of the company's previous offering. Nvidia also detailed a new set of software tools to help developers sell artificial-intelligence models more easily to firms that use its technology. Nvidia is working with contract chip manufacturer TSMC to avoid bottlenecks in packaging chips that slowed shipments of its previous flagship AI processor, Huang said. \"The volume ramp in demand happened fairly sharply last time, but this time, we've had plenty of visibility\" into demand for Blackwell chips, Huang said. Some analysts said Wall Street has already factored in the debut of the B200 Blackwell chip, which the company claims is 30 times faster at some tasks than its predecessor. The Blackwell chip will be priced between US$30,000 and US$40,000, Huang told CNBC. Huang later clarified that comment, saying Nvidia will include its new chip in larger computing systems and that prices will vary based on how much value they provide. \"The Blackwell technology shows a significant performance uplift compared to Hopper (the current flagship chip) but it's always hard to live up to the hype,\" said David Wagner, portfolio manager at Aptus Capital Advisors. In a discussion about Nvidia's cooperation with South Korean chipmakers, Huang said Nvidia is qualifying Samsung Electronics'\u00a0high bandwidth memory (HBM) chips. Reuters reported last week that Samsung's HBM3 series have not yet passed Nvidia's qualification for supply deals. Samsung's cross-town rival SK Hynix on Tuesday said it has begun mass production of next-generation HBM3E chips, with sources saying initial shipments will go to Nvidia this month. At the center of Wall Street's AI euphoria, Nvidia's stock has more than tripled over the past 12 months, making it the US stock market's third-most valuable company, behind only Microsoft and Apple. Even after that meteoric rally, Nvidia is trading at about 35 times its expected earnings, cheap compared with its PE of 58 a year ago, according to LSEG data. That decline in Nvidia's PE valuation is the result of analysts massively increasing their estimates of the chipmaker's future earnings, and if those forecasts turn out to be too optimistic, Nvidia's stock risks plummeting back to earth. Nvidia expects major customers including Amazon.com, Alphabet's Google, Meta Platforms, Microsoft, OpenAI and Tesla to use its new chip. Its hardware products will likely remain \"best-of-breed\" in the AI industry, Morningstar analysts said, lifting their estimates for Nvidia data-centre\u00a0revenue for 2026 and 2028. \"We remain impressed with Nvidia's ability to elbow into additional hardware, software, and networking products and platforms,\" they said. The software push shows how Nvidia, whose chips are mostly used to train large-language models like Google's Gemini, is trying to make its hardware easier to adapt for companies rushing to integrate generative AI into their businesses. Many analysts expect Nvidia's market share to drop several percentage points this year, as competitors launch new products and the company's largest customers make their own chips, although its dominance is expected to remain unchallenged.    Copyright \u00a9 1999-2023 The Edge Communications Sdn. Bhd. 199301012242 (266980-X). All rights reserved "
}