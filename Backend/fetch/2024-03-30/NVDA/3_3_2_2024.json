{
    "title": "ServiceNow, Hugging Face, and NVIDIA Release Open Access LLMs",
    "date": "3/2/2024",
    "url": "https://svdaily.com/2024/03/02/servicenow-hugging-face-and-nvidia-release-open-access-llms/",
    "text": "Silicon Valley Daily News about Silicon Valley business almost everyday. SANTA CLARA\u2014\u00a0ServiceNow,\u00a0Hugging Face, and\u00a0NVIDIA, have announced the release of StarCoder2, a family of open\u2011access large language models (LLMs) for code generation that sets new standards for performance, transparency, and cost\u2011effectiveness. StarCoder2 was developed by the\u00a0BigCode\u00a0community, stewarded by\u00a0ServiceNow, the leading digital workflow company, and Hugging Face, the most\u2011used open\u2011source platform where the machine learning community collaborates on models, datasets and applications. Trained on 619 programming languages, StarCoder2 can be further trained and embedded in enterprise applications to perform specialized tasks such as application source code generation, workflow generation, text summarization, and more. Developers can use its code completion, advanced code summarization, code snippets retrieval, and other capabilities to accelerate innovation and improve productivity. StarCoder2 offers three model sizes: a 3 billion\u2011parameter model trained by ServiceNow, a 7 billion\u2011parameter model trained by Hugging Face, and a 15 billion\u2011parameter model built by NVIDIA with NVIDIA NeMo and trained on NVIDIA accelerated infrastructure. The smaller variants provide powerful performance while saving on compute costs, as fewer parameters require less computing during inference. In fact, the new StarCoder2 3 billion\u2011parameter model also matches the performance of the original StarCoder 15 billion\u2011parameter model. \u201cStarCoder2 stands as a testament to the combined power of open scientific collaboration and responsible AI practices with an ethical data supply chain,\u201d emphasized Harm de Vries, lead of ServiceNow\u2019s StarCoder2 development team, and co\u2011lead of BigCode. \u201cThe state\u2011of\u2011the\u2011art open\u2011access model improves on prior generative AI performance to increase developer productivity and provides developers equal access to the benefits of code generation AI, which in turn enables organizations of any size to more easily meet their full business potential.\u201d \u201cThe joint efforts led by Hugging Face, ServiceNow and NVIDIA enable the release of powerful base models that empower the community to build a wide range of applications more efficiently with full data and training transparency,\u201d said Leandro von Werra, machine learning engineer at Hugging Face and co\u2011lead of BigCode. \u201cStarCoder2 is a testament to the potential of open\u2011source and open science as we work toward democratizing responsible AI.\u201d \u201cSince every software ecosystem has a proprietary programming language, code LLMs can drive breakthroughs in efficiency and innovation in every industry,\u201d said Jonathan Cohen, vice president of applied research at NVIDIA. \u201cNVIDIA\u2019s collaboration with ServiceNow and Hugging Face introduces secure, responsibly developed models, and supports broader access to accountable generative AI that we hope will benefit the global community.\u201d Fine\u2011Tuning Advances Capabilities with Business\u2011Specific Data StarCoder2 models share a state\u2011of\u2011the\u2011art architecture and carefully curated data sources from BigCode that prioritize transparency and\u00a0open governance\u00a0to enable responsible innovation at scale. The foundation of StarCoder2 is a new code dataset called\u00a0The Stack v2\u00a0which is more than 7x larger than\u00a0The Stack v1. In addition to the advanced data set, new training techniques help the model understand low\u2011resource programming languages (such as COBOL), mathematics, and program source code discussions. StarCoder2 advances the potential of future AI\u2011driven coding applications, including text\u2011to\u2011code and text\u2011to\u2011workflow capabilities. With broader, deeper programming training, it provides repository context, enabling accurate, context\u2011aware predictions. These advancements serve seasoned software engineers and citizen developers alike, accelerating business value and digital transformation. Users can fine\u2011tune the open\u2011access models with industry or organization\u2011specific data using open\u2011source tools such as NVIDIA NeMo or Hugging Face TRL. Organizations have already fine\u2011tuned the foundational StarCoder model to create specialized task\u2011specific capabilities for their businesses. ServiceNow\u2019s text\u2011to\u2011code Now LLM was purpose\u2011built on a specialized version of the 15 billion\u2011parameter StarCoder LLM, fine\u2011tuned and trained for ServiceNow workflow patterns, use\u2011cases, and processes. Hugging Face also used the model to create its StarChat assistant. BigCode Fosters Open Scientific Collaboration in AI BigCode represents an open scientific collaboration jointly led by Hugging Face and ServiceNow. Its mission centers on the responsible development of LLMs for code. The BigCode community actively participated in the technical aspects of the StarCoder2 project through working groups and task forces, leveraging ServiceNow\u2019s Fast LLM framework to train the 3 billion\u2011parameter model, Hugging Face\u2019s nanotron framework for the 7 billion\u2011parameter model, and the end\u2011to\u2011end NVIDIA NeMo cloud\u2011native framework and\u00a0NVIDIA TensorRT\u2011LLM\u00a0software to train and optimize the 15 billion\u2011parameter model. Fostering responsible innovation is at the core of BigCode\u2019s purpose, demonstrated through its open governance, transparent supply chain, use of open\u2011source software, and the ability for developers to opt data out for training. StarCoder2 was built using responsibly sourced data under license from the digital commons of\u00a0Software Heritage, hosted by\u00a0Inria. \u201cStarCoder2 is the first code generation AI model developed using the Software Heritage source code archive and built to align with our policies for responsible development of models for code,\u201d stated Roberto Di Cosmo, Director at Software Heritage. \u201cThe collaboration of ServiceNow, Hugging Face, and NVIDIA exemplifies a shared commitment to ethical AI development, advancing technology for the greater good.\u201d StarCoder2, as with its predecessor, will be made available under the BigCode Open RAIL\u2011M license, allowing royalty\u2011free access and use. Furthermore, the supporting code for the models resides on the BigCode project\u2019s GitHub page. All StarCoder2 models will also be\u00a0available for download\u00a0from Hugging Face and the StarCoder2 15B model is available on\u00a0NVIDIA AI Foundation models\u00a0for developers to experiment with directly from their browser, or through an API endpoint. California remains the most populous state in the nation from new figures by the U.S. Census Department. According to the U.S. Census Bureau\u2019s Vintage 2021 national and state population estimates and components of change, the population of the United States grew in the past year by 392,665, or 0.1%, the lowest rate since the nation\u2019s [\u2026] MOUNTAIN VIEW\u2014 Intuit Inc., the financial software company known for TurboTax,\u00a0QuickBooks,\u00a0Mint\u00a0and\u00a0Credit Karma, is getting into the venture capital business with the launch of Intuit Ventures, its corporate venture capital arm. Intuit Ventures will help accelerate innovation for businesses and consumers through the companies it invests in, driving future innovations for consumers and small businesses. The [\u2026] LEIXLIP, Ireland \u2014 Intel has begun using Intel 4 technology at its new Fab plant in Ireland, which deploys extreme ultraviolet (EUV) technology, and the first use of EUV in high-volume manufacturing (HVM) in Europe. The new technology paves the way for future products like Intel\u2019s upcoming Intel Core Ultra processors (code-named Meteor Lake), which [\u2026]  "
}