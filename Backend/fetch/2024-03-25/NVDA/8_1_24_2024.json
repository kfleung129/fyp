{
    "title": "Nvidia: Equinix Private AI Service Will Help Partners Close DGX System \nDeals 'Faster'",
    "date": "1/24/2024",
    "url": "https://www.crn.com/news/data-center/2024/nvidia-equinix-private-ai-service-will-help-partners-close-dgx-system-deals-faster",
    "text": "The new service is meant for businesses that want privately-owned AI supercomputers but lack the data center infrastructure and expertise to support the systems. Nvidia executive Charlie Boyle tells CRN it will help channel partners \u2018make money faster, close business faster and, at the end, deliver more value to their customers.\u2019  Nvidia and Equinix said they have created a solution for businesses that want to quickly set up privately-owned supercomputers to build generative AI applications but lack the data center infrastructure and expertise to support the systems. Announced and launched on Wednesday, Equinix Private AI with Nvidia DGX is described by the two companies as a \u201cturnkey\u201d solution in which Equinix hosts and manages Nvidia DGX supercomputers purchased by businesses through Nvidia channel partners. It\u2019s made for businesses that don\u2019t want their data in the public cloud for various reasons, including security, data sovereignty and auditability. [Related: Analysis: How Nvidia Showed Its True Power In 2023] Charlie Boyle, vice president of DGX systems at Nvidia, told CRN that the new solution will help partners in the Nvidia Partner Network \u201cmake money faster, close business faster and, at the end, deliver more value to their customers\u201d with DGX systems. \u201cIt makes it easier for them to sell and close business. And it makes it much easier for customers to consume and get up and running with AI, so this is going to be tremendous for all of our [Nvidia Partner Network] partners to accelerate business they've been working on for months and getting new business into their pipelines,\u201d he said. With the fully managed service, the AI chip giant and data center powerhouse are hoping to solve problems they see many businesses facing: the significant amount of time it takes to plan and deploy a cluster of Nvidia DGX systems in a private data center, the lack of proper facilities to house such systems and a lack of personnel to manage them. \u201cCustomers want world-class AI capabilities, but most of them don't have the data center infrastructure, the expertise to build, manage and run those systems,\u201d Boyle said in a briefing. Jon Lin, executive vice president and general manager of data center services at Equinix, said with his company\u2019s expertise in setting up and managing data centers, the new Private AI service can reduce the lead time for deploying DGX supercomputers \u201cfrom months to weeks or potentially days.\u201d Equinix\u2019s Private AI service is focused on Nvidia\u2019s DGX BasePod or SuperPod cluster configurations, the latter of which can range from 128 DGX H100 systems to as many as 2,048 systems, according to Nvidia documentation. These DGX systems, each of which contain eight H100 GPUs, are connected together using Nvidia\u2019s ultra-low latency InfiniBand networking technology and managed by Equinix\u2019s managed services team of more than 800 employees across the globe. Another critical component of the service is Nvidia AI Enterprise, the chip designer\u2019s software platform that includes all the building blocks they need to train and run AI models, from the NeMo framework for building large language models to the TensorRT-LLM library for optimizing such models. Customers of the Private AI service can deploy their DGX clusters at nearly 250 of Equinix\u2019s International Business Exchange data centers worldwide, which includes locations in North America, South America, Europe, Asia and Africa, according to the data center company. DGX clusters housed within Equinix\u2019s data centers are connected to the outside world through a high-speed private network, and the company also provides high-bandwidth interconnections to cloud services and enterprise service providers. The service comes with \u201centerprise-grade\u201d support and security, which includes assistance from Equinix staff on building and deploying custom AI models as well as access to Nvidia experts. \u201cWe're hearing tremendous amounts of energy and vigor from enterprises around wanting to do this but in a way that is not exposing them from either a cybersecurity perspective [or] from an intellectual property leakage perspective, etc. That private infrastructure then becomes a critical path to be able to deliver that,\u201d Lin said. While Nvidia and Equinix are pitching the Private AI service as a fast and simple way for businesses to set up privately-owned AI infrastructure, it won\u2019t have an impact on lead times for delivery of DGX systems, according to Boyle. \u201cAll DGX SuperPOD customers get the same lead time from order to shipment of systems, regardless of where the deployment will occur,\u201d he told CRN. Long lead times for systems containing Nvidia\u2019s H100 GPUs, including DGX, have been a common complaint of OEMs and channel partners for the past year. This has been due to high demand for the processors, which have been popular with untold scores of AI developers, including big names like OpenAI, due to their high-performance capabilities. Nvidia has been making efforts to increase production of H100s over the past several months to keep up with demand, but partners have told CRN that they still face long lead times. \u201cYou\u2019re just selling a backorder, a place in line,\u201d said an executive at one Nvidia partner, who asked to not be named so that he could speak frankly about business with the chip designer. An executive at another Nvidia partner said lead times are improving for H100-based systems, but he is still quoting customers four to eight weeks for deliveries \u201cto be conservative.\u201d In some instances, systems are shipping faster, he added. "
}