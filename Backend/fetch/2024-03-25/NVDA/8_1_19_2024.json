{
    "title": "Do upstart chip makers stand a chance in the semiconductor market dominated \nby Big Tech firms?",
    "date": "1/19/2024",
    "url": "https://www.thehindu.com/sci-tech/technology/do-upstart-chip-makers-stand-a-chance-in-the-semiconductor-market-dominated-by-big-tech-firms/article67756008.ece",
    "text": "To enjoy additional benefits CONNECT WITH US January 19, 2024 05:24 pm | Updated 05:24 pm IST COMMents SHARE READ LATER FILE PHOTO: In Silicon Valley, a company\u2019s status in the AI industry was dictated by the number of Nvidia GPUs they owned.\u00a0\n| Photo Credit: Reuters All along last year, in Silicon Valley, a company\u2019s status in the AI industry was dictated by the number of Nvidia-made graphic processing units or GPUs they owned. Microsoft, Amazon, Meta and Tesla are \u201cGPU-rich\u201d. Nvidia, a company pivoted from making hardware for games and graphics to manufacturing AI chips in 2010 is reaping the reward of its prescient strategy. Currently, the company has about 70% of the market share on GPUs. (Their third-quarter results reported in November-end showed a year-on-year growth of 206% in revenue.) But Big Tech firms are not just relying on Nvidia. In fact, Amazon, Microsoft, Alphabet and Meta have all either unveiled their own custom AI chipsets or have planned to launch one soon. Google\u2019s latest and most powerful AI model Gemini, announced in December, was trained using the company\u2019s own tensor processing unit, or TPU, chip. (Google claims TPUs to be the next generation of GPUs.) Given this backdrop, what role can upstart chip makers play in a market dominated by tech giants? (For top technology news of the day,\u00a0subscribe\u00a0to our tech newsletter Today\u2019s Cache) \u201cUpstart companies have their task cut out by a bit,\u201d said\u00a0Sangeet Paul Choudhary, management consultant and author of Platform Scale. \u201cAs companies look to target an enterprise audience and build highly fine-tuned models, they will look to build purpose-fit AI chips that best deliver performance within that context. This will drive greater vertical integration overall.\u201d Nvidia\u2019s demand isn\u2019t just bolstered by chips - it is a one-stop-shop for developers. \u201cGetting vertical play right involves engaging the whole ecosystem. In Nvidia\u2019s case, it has much higher uptake in research [based on citations], has higher developer engagement, even more so now with the Hugging Face partnerships. Cuda [a programming model that helps compute GPUs] is the most preferred toolkit by developers. [So,] just building better chips won\u2019t cut it,\u201d he added. Investors who were already wary, were reportedly staying away from a tough industry, which has been made even harder by Nvidia.\u00a0Pitchbook data showed that U.S. chipmaking startups raised $881.4 million until August-end 2023, a considerable decline from $1.79 billion during the first three quarters of 2022. The number of deals had also dropped from 23 to just four during the same period. But the sluggishness wasn\u2019t just contained to funding for chipmaking.\u00a0According to PitchBook\u2019s First Look data packs, global VC funding for the fourth-quarter fell to roughly $345 billion, down from $531 billion in 2022. \u201cThe funding requirements for AI chipmaking companies is generally very high and can be as high as 8\u201310 times that of a startup at the initial stage due to large investment requirement in R&D. Moreover, it takes at least two years to develop a medium-complexity chip. These factors result in a longer wait time for investors to reap the rewards, that too at a higher risk,\u201d said Madhukar Bhardwaj, principal investor at Physis Capital. While Nvidia\u2019s dominance is evident and that it is making it difficult for other companies to attract funds it is worth noting \u201cthat the market is always receptive to innovators with revolutionary products,\u201d he said. In September, Santa Clara-based AI chip startup d-Matrix raised $110 million in its Series B funding round led by Singapore\u2019s Temasek, Microsoft and Playground Global. The startup was not focused on training massive AI models, instead it chose to do something specialised - inferencing i.e., making predictions from the data. In August, another AI hardware startup, Tenstorrent founded by pioneering chip architect Jim Keller raised $100 million in a convertible note funding round co-led by Hyundai Motor Group and Samsung Catalyst Fund. The startup recently started a service which allows clients to use AI models without buying them. A spokesperson for the firm said, \u201cWhile Nvidia is currently a dominating force in the AI\u00a0chip industry, we do believe there\u2019s still room for viable competitors to rise up. We think the way to compete with Nvidia is to deliver a full solution (hardware and software) without requiring the user to change their workflow. We think we can challenge\u00a0Nvidia with an open-source platform.\u201d OpenAI CEO Sam Altman signed a deal worth $51 million with a chip startup Rain Neuromorphics. The company is developing a neuromorphic processing unit or NPU, a chip that replicates the human brain in its form. NPUs promise 100 times more computing power and 10,000 times more energy efficiency as compared to GPUs. There are other young companies that have risen to the challenge - Tiny Corp. designs ARM-based training and inference chips for edge computing; Modular develops parallel accelerator chips for training and inference (both offer speed at low cost and are viewed as alternatives to Nvidia\u2019s Cuda). Another startup called MatX designs neural network inference chips focused on edge applications. \u201cThis is just the beginning of what we are seeing in this industry. I am sure there is much more to come. Despite the perception that Nvidia has a monopoly, I believe the next five years will be a ramp-up. The AI chipmaking pie is a huge one, and Nvidia\u2019s portion even if big is a part of what the market forecast is of a $200-300 billion industry over the next decade,\u201d Ashok Chandak, president of the IESA or Indian Electronics and Semiconductor Association said. Chandak believes there are several factors behind this: \u201cFirstly, competencies will build up. We will see AI applications in healthcare, automotive and robotics; this isn\u2019t just restricted to large language models. Secondly, GPUs aren\u2019t the only source of compute. Depending on the use case, there are CPUs from Intel or AMD, so there\u2019s plenty of opportunity. Thirdly, edge computing will grow scope-wise and percolate to smaller applications like smart cameras or medical instruments or safety tools,\u201d he explained. Nvidia has woken the industry up and will be an enabler in the long run, he noted. COMMents SHARE technology (general)\n\n/\n\ninternet\n\n/\n\nArtificial Intelligence\n\n/\n\nemerging technologies BACK TO TOP Terms & conditions\u00a0\u00a0|\u00a0\u00a0Institutional Subscriber Comments have to be in English, and in full sentences. They cannot be abusive or personal. Please abide by our community guidelines  for posting your comments. We have migrated to a new commenting platform. If you are already a registered user of The Hindu and logged in, you may continue to engage with our articles. If you do not have an account please register and login to post comments. Users can access their older comments by logging into their accounts on Vuukle. "
}