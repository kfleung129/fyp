{
    "title": "Meta plans new Artemis AI chip to break away from Nvidia",
    "date": "2/1/2024",
    "url": "https://interestingengineering.com/innovation/meta-plans-new-in-house-ai-chip-artemis-to-break-away-from-nvidia",
    "text": "Meta, the world\u2019s largest social media network, has been investing heavily in boosting its computing power to support its ambitious AI vision. Kira-Yan/iStock By subscribing, you agree to our Terms of Use and Policies You may unsubscribe at any time. Meta, the parent company of Facebook, is gearing up to unleash a new breed of artificial intelligence (AI) chip into its data centers this year, a leaked document revealed on Thursday. As per Reuters, the chip, dubbed \u201cArtemis,\u201d is the second generation of a custom silicon line that Meta unveiled last year. It could give Meta an edge over its rivals by reducing its reliance on Nvidia\u2019s dominant chips and curbing the soaring costs of running AI applications. Meta, the world\u2019s largest social media network, has been investing heavily in boosting its computing power to support its ambitious AI vision. It wants to create immersive and interactive experiences for its billions of users across Facebook, Instagram, WhatsApp, and futuristic hardware devices like the Ray-Ban smart glasses. Despite its ongoing multibillion-dollar loss, Reality Labs, Meta\u2019s division for AR, VR, and the metaverse, recorded its most profitable quarter to date. The company\u2019s revenue exceeded $1 billion in Q4 of 2023, driven by the successful sales of its Quest headsets and Ray-Ban Meta smart glasses. But to make that happen, Meta needs a lot of specialized chips and energy to run its AI models, which can generate realistic images, videos, sounds, and texts. This has become a huge drain on its resources and profits as it competes with other tech giants for the scarce and expensive chips in the market. During Meta\u2019s earnings call on Thursday, Mark Zuckerberg shared the company\u2019s strategy for winning the high-stakes AI arms race against Alphabet and Microsoft. Meta\u2019s competitive edge lies in its walled data garden, with hundreds of billions of publicly shared images and tens of billions of public videos. Zuckerberg took a not-so-subtle dig at competitors like Google, Microsoft, and OpenAI that rely on training their AI models on public web data crawled by their search engines every day. According to Dylan Patel, founder of the silicon research group SemiAnalysis, Meta could save hundreds of millions of dollars in energy bills and billions of dollars in chip purchases if it can successfully deploy its chip at scale. Meta confirmed its plan to roll out the updated chip in 2024, saying it would work alongside the hundreds of thousands of off-the-shelf graphics processing units (GPUs) \u2013 the default chips for AI \u2013 it was acquiring. \u201cOur internally developed accelerators are designed to complement the commercially available GPUs and deliver the best performance and efficiency for Meta-specific workloads,\u201d a Meta spokesperson said. Meta CEO Mark Zuckerberg said last month that the company would have about 350,000 of Nvidia\u2019s flagship \u201cH100\u201d processors, the most coveted GPUs for AI, by the end of the year. He said that Meta would have the equivalent of 600,000 H100s in total, along with other suppliers. The launch of its chip is a welcome development for Meta\u2019s in-house AI silicon project, which faced a setback in 2022 when the company scrapped the first version of the chip. Meta decided to buy billions of dollars worth of Nvidia\u2019s GPUs instead, which have a near monopoly on an AI process called training. Training involves feeding massive amounts of data into models to teach them how to perform tasks. The new chip, Artemis, can only do another process called inference when the models use their algorithms to make decisions and generate outputs. Reuters reported last year that Meta is also working on a more advanced chip, like a GPU, that can train and infer. Meta shared some details about the first generation of its Meta Training and Inference Accelerator (MTIA) program last year, calling it a learning opportunity. According to Patel, despite some initial hurdles, a chip like Artemis could be significantly more efficient than Nvidia\u2019s energy-consuming processors in executing Meta\u2019s recommendation models. He added that such a chip could save a considerable amount of money and energy currently being wasted. "
}