{
    "title": null,
    "date": "1/29/2024",
    "url": "https://www.telegraph.co.uk/business/2024/01/29/driverless-cars-ai-artificial-intelligence-tesla-apple/",
    "text": "The dangerous self-driving experiment is turning us all into human guinea pigs Who wants to be a human guinea pig? It involves a new kind of robot which may maim and kill you, but on the plus side, you\u2019ll get a chance to participate in an exciting foray in innovation. Don\u2019t all rush at once. The ethics of medical experiments that pose a danger to participants, such as challenge trials, are debated at great length. And rightly so. Yet we may soon become unwilling test\u00a0subjects for a technology that looks more dubious by the day. Parliament has begun debating the Automated Vehicles Bill, announced in the King\u2019s Speech last year. It\u2019s intended to coax self-driving vehicles onto our roads by providing a clear legal framework. The Government touts autonomous driving as \u201cthe future of transport, aiming at safer, greener and more efficient travel for all\u201d, and it doesn\u2019t want Britain to miss out on either the consumer benefits or the economic potential. In reality, we\u2019ve been here before. Steam locomotives caused\u00a0a death on their very first day of public operation, when the MP William Huskisson fell under Stephenson\u2019s Rocket. The first pedestrian to be killed by an automobile in the UK was struck with a vehicle moving at just 4mph. Extinguishing the risk to the public from innovations in mass transportation is clearly impossible - they\u2019re designed to go everywhere, so accidents can happen anywhere. A balance is needed. But recent developments in the US have made regulators think twice. Not so long ago, pundits and image-conscious policy wonks regarded autonomous driving as the cornerstone of a \u201cfourth industrial revolution\u201d encompassing AI and smart cities. But no sooner had the dream inched\u00a0towards reality than things became ugly. Just weeks after San Francisco permitted the deployment of General Motors\u2019 Cruise robo-taxis last August - after years of human-supervised trials - then a grisly incident obliged it to call a halt. A pedestrian was dragged 20 feet under a Cruise taxi which had failed to stop. Regulators had only received partial footage of the collision from GM \u2013 and not the really nasty part \u2013 and so suspended the company\u2019s licence. A third party report into the incident last week suggested that ropey internet was probably why regulators didn\u2019t get the full details. But nevertheless, it found serious management failings at Cruise on multiple levels. The worst of these was an ingrained hostility to co-operating with a regulator. Cruise was banned from operating in the state in October, and in December announced 900 job cuts. It\u2019s just the latest in a long line of industry retrenchments. Some $100bn (\u00a379bn) has been spent on self-driving vehicles over the past decade. Only last week, Bloomberg reported that Apple is scaling back its autonomous driving software project Titan, and pushing back the internal launch date to 2028. The report states that at best the software will perform what the industry classifies as Level 2 functions - partial automation such as steering and acceleration assistance. Big deal. Partial driving is a widely recognised problem, as the RAC Foundation notes. Humans who have turned off their attention can only switch it back on very slowly. Such problems have obliged Tesla to recall cars over its partial self-driving tech, the most recent a giant two million-vehicle recall in December following a safety agency investigation. Despite the many billions of dollars spent on self-driving technology projects over more than a decade, not one truck driver has yet been replaced. \u201cProgress in this technology has failed to meet many of its promoters\u2019 predictions,\u201d the Transport Select Committee observed last November. Edison analyst Richard Windsor says that the fundamental technical issue is a reliance on deep learning, the basis of generative AI systems. This just isn\u2019t reliable enough to create a safer-than-human robot driver in real world conditions. We shouldn\u2019t allow the astonishing mimicry of large language models such as ChatGPT to distract us from the corresponding progress in machine vision. To borrow an idiom: if you\u2019re so smart, how come you keep crashing? It\u2019s also exposed a moral black hole. Only a few years ago, the venture capital class and their lackeys were arguing that \u201cwe\u2019re going to have to be more forgiving of a car causing a fatality\u201d if it was a self-driving car. Because progress. As the Tesla biographer Ed Niedermeyer observed in 2019, \u201cthe tech sector has lost its ability to anticipate the negative consequences of its innovations\u201d, and was instead \u201cblitz-scaling its way toward a technological dystopia\u201d. The story reverses the familiar mythology of innovation and regulation. We know all about regulators inhibiting innovation \u2013 but these days, they are so keen to be seen as the first, and polish their resumes, they risk putting the public in danger for no good reason. Fortunately the Autonomous Driving Bill is aware of these issues. It calls out mis-labelling of autonomous features \u2013 something Tesla has been criticised for \u2013 and there\u2019s a requirement to provide information to regulators. But not enough, according to the select committee. Lords confirmed to me last week that much more detail is needed.\u00a0 As is continuing scrutiny. Regulators are rueing\u00a0the decision to let the companies mark their own homework. The Department for Transport still hopes that half of our car journeys by 2047 could be autonomous. But it may turn out to be like a 1970s council skateboard park, built for skateboarders who never come. "
}